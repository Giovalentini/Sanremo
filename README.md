# Churn prediction
*A predictive model for disinvestment probability.*

The model generates a **churn probability score** for each active customer. The score is a number **between 0 and 1**, where 0 means the customer will certainly not churn and 1 means the customer will surely churn.

For the purpose of this use case, we define a churn as **anytime a customer completes the disinvestment journey on our platform**. It was calculated that one click on the *disinvest* button resolves in a loss of **20K AUM**.

The model's **output** is available in the Redshift table `predictive_analytics.churn_scores`.

## Churn descriptive analysis
An analysis of the churn broader topic can be found [here](https://docs.google.com/spreadsheets/d/1dVQ9c3_oCjPQXSC4VNWwJRfeoJ8av5CDte3OqdL0Uyg/edit?usp=sharing). Main outcomes:
- From January to August 2021, 7038 disinvestments out of 51059 active customers (13.78%)
- An average of 22 IT and 15 UK disinvestments per day (37)
- Approx. cost of 'clicking disinvest' is equal to 20 k
- 44% of disinvestments come from Tier 1 Eligible customers
- Disinvestment amount ratio correlates with the Volatility Index lagged to the prior month 
- Disinvestment amount ratio negatively correlates with Portfolio Performance

## Model specification
### Problem statement - what is the model predicting?
The model is predicting the probability that an active customer will **complete a disinvestment journey on our platform** in the **7 days following the day when the prediction is generated** (*reference date*).

These constraints help to set clear boundaries for the problem statement and provide an actionable score in output. They were set based on the following logic:
- **complete the disinvestment journey** to focus on the last event after which the customer decision is made and it's no longer possible to take an action. The model could be trained on the outflows target variale, but when an outflow is recorded in our DWH is already too late to take any action on the customer.
- **time window of 7 days** 
    - to create a score which is reactive to changes in customer behaviour and can actually drive actions, performed by CRM or digital marketing teams
    - to technically frame the problem in way that is machine learnable - the wider the time window, the harder to create a prediction
 
The **target variable** is therefore defined as follows:
- 1 if the customer completed a disinvestment journey in our platform the 7 days after reference date
- 0 if the customer did not complete a disinvestment journey in our platform in the 7 days after reference date

More details on target variable definition can be found [here](https://moneyfarm.atlassian.net/browse/DS-655).

### Learning algorithm
The chosen model is a [light gradient boosting machine](https://lightgbm.readthedocs.io/en/latest/). The model specification can be found in the [ml_models.py](https://gitlab.com/moneyfarm-tech/data/churn_prediction/-/blob/master/src/ml_models.py) file alongside a set of different options for model specification.

#### Cross validation
The model training enforces a 5 fold cross validation procedure. As a result, 5 different models are generated. The final prediciton is calculated as the average of the 5 predictions generated by each of those models. This helps to preventively address overfitting and achieve bettere generalization.

### Training set and features
The model is trained over a time window of 6 months. Alongside with the above defined target variable, for each active customer is created a set of features. Such features are partly extracted directly from the DWH and partly calculated through a [feature engineering](https://gitlab.com/moneyfarm-tech/data/churn_prediction/-/blob/master/src/feature_engineering.py) process.

There are the following types of features:
- **descriptive features** such as customer age, occupation, type of income. These features aim to track static traits of our customers.
- **engagement features** such as number of logins in the past two weeks or two months. There features aim to track how our customers interact with our platforms.
- **beahavioural features** such as difference between average number of logins in the past two weeks and average number of logins in the past two months. These features aim to flag up customers who significantly changed their behaviour in the two weeks before reference date.
- **portfolio features** number of portfolios, risk class, investment time horizon, performances
- **active promo** active promotions and mgm

The creation of training set and feature engineering are orchestrated by:
- [sql queries](https://gitlab.com/moneyfarm-tech/data/churn_prediction/-/tree/master/src/sql)
- [python function in the utils library](https://gitlab.com/moneyfarm-tech/data/churn_prediction/-/blob/master/src/utils.py#L172)
- [feature engineering script](https://gitlab.com/moneyfarm-tech/data/churn_prediction/-/blob/master/src/feature_engineering.py)

#### Exploratory data analysis
An EDA can be found in [this notebook](https://gitlab.com/moneyfarm-tech/data/churn_prediction/-/blob/master/src/notebooks/EDA.ipynb). 

#### Feature selection
The final algorithm includes the full features set, this being the configutaion with the best ROC-AUC performance metric. Inputs on feature selection can be found here:
- [correlation matrix](https://docs.google.com/spreadsheets/d/1ev_wwy1yP59oBO5fBWfwMm7Ji1XDjsvHPDISKem5q5Y/edit?usp=sharing)
- [feature importance](https://docs.google.com/spreadsheets/d/1Nn3LEQu2u9xFbDd0kjmTqsgpCA49IzejXlvq_M63Sg0/edit?usp=sharing) extracted from linear model approach (OLS)

#### Imbalanced classification
This is an imbalanced classification problem: for a number of active customer in the range of 60K, we have [roughly 22 daily disinvestment for IT and 15 for UK](https://moneyfarm.atlassian.net/browse/DS-656). This means only a very small portion of active customers is disinvesting, and translates in extremely limited number of example of disinvestments the model could learn from. With a similar setup, it would not be possible to train a predictive model.

This was addressed training the model over a time window of 6 months with the following approach:
- any customer who, in that time window, did at least one disinvestment is tagged as churn and assigned the label of 1
- any other customer is tagged as not churn and assigned the label of 0.

This allowed a rebalancing of the dataset that resulted, in july 2021, in a dataset with:
- 41K examples of negative class (label = 0, not churn)
- 4K example of positive class (label = 1, churn)

In this context, the model can learn from roughly 9% of observations in training set belonging to positive class. As a drawback, the predictive model will provide scores skewed towards high value.

## Resources
[This confluence page](https://moneyfarm.atlassian.net/wiki/spaces/DKB/pages/2992963605/Churn+model+resources) links to the relevant resources in terms of:
- DWH tables
- Metabase
- Tableau
- Google Drive
- Gitlab
- Matillion

## Techincal setup
There are two procedures relevant for model's functioning: **training** and **scoring**.

**Scoring** procedure is about scoring the active customer base at a specific date, usually set to `today()`.

**Training** procedure is about training the model, based on historical data. 

More info on deployment and orchestration is presented in the [dedicated confluence page](https://moneyfarm.atlassian.net/wiki/spaces/DKB/pages/2993160260/Churn+model+engineering+approach).

## How to run the application locally
Open a terminal window and type in the following commands:
- **sh churn_notebook.sh** will spin up a jupyter notebook instance, useful for performing analysis and developing.
- **ml_score.py** script can be launched by a terminal window. It will score customers for churn at the reference date of `today()`

## JIRA epics
The project is tracked on tickets from the following epics:
- [Churn prediction prototype](https://moneyfarm.atlassian.net/browse/DS-652)
- [Churn prediction deployment](https://moneyfarm.atlassian.net/browse/DS-871)